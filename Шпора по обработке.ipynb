{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyME6C3tspWBIhzStRlBNAl4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vitalyastiy/cheat/blob/main/%D0%A8%D0%BF%D0%BE%D1%80%D0%B0%20%D0%BF%D0%BE%20%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYjoo6FZzUnL"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "#### импорт библиотек и загрузка данных во фрейм ####\n",
        "from itertools import count\n",
        "from multiprocessing import cpu_count\n",
        "import pandas as pd\n",
        "data2 = pd.read_csv(r\"C:\\Users\\....Desktop\\nnn\\NN.csv\" \\\n",
        "    , sep=',' , encoding='latin-1') #, index_col=0 - индекс \n",
        "data2.head(3)\n",
        "#%%\n",
        "'''data = pd.read_csv(r\"C:\\Users\\...Desktop\\nn\\02-03_new — копия.csv\" \\\n",
        "    , sep=',' , encoding='latin-1') #, index_col=0 - индекс \n",
        "data.head(3)'''\n",
        "# data_copy[:10].to_csv('saved_ratings.csv', index=False) # экспортироватъ первые десятъ строк\n",
        "# data_copy = data.copy(deep=True) #shallow - поверхностное копирование фрейма \n",
        "\n",
        "#data1.to_csv('02-03_new.csv', header=True, index=False) # экспорт в csv\n",
        "# %%\n",
        "\n",
        "######### Переименовать данные \n",
        "data=data.rename(columns={\"Mean_flag_integrity 4G (%)\": \"flag\"}) # переименовать\n",
        "data= data.rename(columns={\"gkgk\": \"colu\"}) # - переименоватъ столбец\n",
        "data.rename(columns=dict(sector_name='region', region='locale')) # - переименоватъ столбец\n",
        "data.rename(index={0: 'firstEntry', 1: 'secondEntry'}) # переименовать индекс\n",
        "data.rename_axis('inde', axis='rows') # переименовать название \n",
        "\n",
        "#########   Работа с выбором значений \n",
        "data.sample(5) # data.head(5) # data.tail(5)  # выбор выборки\n",
        "data.head(3) # - вывести первые 3 записи\n",
        "data_copy.tail(1) # - вывести последнюю записъ\n",
        "data[1:4] # - вывести топ значений фрейма \n",
        "\n",
        "######## |Первичный Анализ \n",
        "data.columns.tolist() # - получитъ наименования столбцов списком\n",
        "data.acell.value_counts() # - подсчет количества уникалных значений\n",
        "len(data) # - вывести количество строк во фрейме \n",
        "len(data['t2.ne_id'].unique()) # - количество уникалъных строк во фрейме \n",
        "data.info() # - получение сведений о фрейме \n",
        "data.describe # - статистическая информация о фрейме\n",
        "data ['acell'].tolist() # - перевести в список стлбец \n",
        "data['colu'] = True # - добавитъ столбец во фрейм данных\n",
        "data2= data[['acell', 'colu']] # - создание нового фрейма из подмножества\n",
        "data2.drop(['colu'], axis=1).head() # - удаление столбца из фрейма данных\n",
        "data2.append(data2.sum(axis=0), ignore_index=True) # - сумма по столбцу\n",
        "data[data['acell'].isin(['NN002998_I','NN002998_I'])] # -филътр\n",
        "data[data['acell'] == 'NN002998_I'] #(><) -филътр, для единственного значения\n",
        "data.sort_values('acell', ascending=True) # - сортировка фрейма \n",
        "data['t2.ne_id'].astype('float') # - изменить тип данных\n",
        "data['sector_name'].fillna('NaN').value_counts().sort_values(ascending=False) # найти NaN\n",
        "\n",
        "## группировка с выводом стат. данных\n",
        "data.groupby('t1.acell').count()\n",
        "data.groupby('t1.acell').mean()\n",
        "data.groupby('t1.acell').median()\n",
        "\n",
        "## подчсчитать количество нулевых значений\n",
        "m_data = data[data['sector_name'].isnull()]\n",
        "n_data = len(m_data) # v1\n",
        "\n",
        "n_data = data.sector_name.isnull().sum() # v2\n",
        "m_data = pd.isnull(data.sector_name).sum() # v3\n",
        "\n",
        "## объеденение данных:\n",
        "pd.concat([df1, df2], ignore_index=True)  # - union\n",
        "sum_df = pd.merge(df1, df2, how='inner', left_on=['t1.region', 't1.acell'] \\\n",
        ", right_on = ['Region','ACELL']) # merge\n",
        "data1 = pd.concat([data, data2]) # union\n",
        "\n",
        "###кейс с фильтрацией:\n",
        "data['t1.region'].unique() #  вывести уникальные значения фрейма\n",
        "data = data.set_index('t1.region') # присвоить индекс\n",
        "data.drop(['RYAZAN', 'TVER'],axis = 0) # установить фильтрацию по столбцу и дропнуть эти данные во фрейме \n",
        "\n",
        "\n",
        "## метод фильтрации квери\n",
        "region = 'Center'\n",
        "quat = '2022-01-01'\n",
        "df_tall_named_sec = df_cor.query('Region == @region & Quarter == @quat')\n",
        "df_tall_named_sec\n",
        "\n",
        "\n",
        "\n",
        "##### Детальный анализ и группировка\n",
        "data.groupby('t1.acell').count() # - группировка для фрейма\n",
        "\n",
        "# группирвка таблицы:\n",
        "data.groupby([\"t1.acell\"]).agg({\n",
        "  \"t2.ne_id\": \"sum\",\n",
        "  \"t1.region\": \"count\",\n",
        "  \"t1.macroregion\": \"last\"\n",
        "}).reset_index()\n",
        "\n",
        "# Перебор строк во фрейме()\n",
        "for idx,row in df2[:1].iterrows():\n",
        "    print(idx, row)\n",
        "#%%\n",
        "############### loc/iloc     ##############\n",
        "data.iloc[:0]  # вывести шапку \n",
        "data.iloc[552] # вывод СПИСОК строки по номеру\n",
        "data.iloc[552] # вывод строки по индексу\n",
        "data.iloc[0:5] # вывести первые 5 значений, с 0 до 4  \n",
        "data.loc[0:5]  # вывести первые 6 значений, с 0 до 5\n",
        "\n",
        "data.recdate  #data['recdate'] #data.iloc[:,0]#  вывод столбца в формате списка\n",
        "data.iloc[2,1] # data.loc[2,'ACELL'] вывести 3 строку из 2-ого столбца \n",
        "data.iloc[:3,1] #data.iloc[0:3,1]#data.iloc[[0,1,2],1]  вывести количество строк из столбца\n",
        "data.iloc[-3:,1] #  вывести второе значение снизу, второго столбца\n",
        "data.iloc[:, 0:2] # вывести всю информацию по двум столбцам  \n",
        "data.iloc[3, [1, 2, 3]] # список третьей строки по первым 3м столбцам\n",
        "data.loc[1:5, 'ACELL': 'Region'] # вывод таблицы с первой по пятаю, 2 столбца \n",
        "\n",
        "data.iloc[[0]] # вывести первую строку\n",
        "data.loc[:,['recdate','ACELL','Region','flag']] # print all\n",
        "data.loc[data.flag.isin(['100', '50'])] # филътр несколъко условий\n",
        "data.loc[data.flag.isnull()] \n",
        "data.loc[data.flag.notnull()]  \n",
        "data[data['t2.ne_id'].isnull()] # вариация поиска нулевых значений\n",
        "\n",
        "############## Примеры фильтров выводом фрейма \n",
        "data.loc[data['ACELL'] == 'NN000231_A'] # вывести отфильтрованную таблицу\n",
        "data.loc[data.ACELL == 'NN000231_A'] # то же что и предыдущее\n",
        "data.loc[data.flag == '0'] # филътр на таблицу с выводом всего датафрейма \n",
        "\n",
        "data.loc[(data.flag == '0') & (data.recdate =='2022-02-28 23:00')] # склеенный фильтр на таблицу\n",
        "data.loc[(data['ACELL'] == 'NN000231_A' ) & (data['recdate'] == '2022-02-20 16:00')\\\n",
        "    , 'recdate':'flag'] # пример склеенного фильтра\n",
        "\n",
        "###### replace ###### \n",
        "data.loc[data['ACELL'] == 'NN000231_A'] = 'BIG'\n",
        "data.loc[data['ACELL'] == 'NN000231_A', 'ACELL':'Mean_flag_integrity 4G (%)'].head() # пример реплэйса с фильтром и выводом\n",
        "\n",
        "############# группировка данных\n",
        "data.groupby('report_date').report_date.size() #(count-разница?) вывести количество записей, аналог гроуп бай\n",
        "data.groupby('t1.acell')['t2.ne_id'].max().sort_index() # присваиваем индекс аселу и выводим макимальное значение из не_ид, сортируем от меньшего \n",
        "data_e = data.groupby(['t1.acell']).ne_id.agg([len, min, max]) # группировка с агрегацией и расчетом \n",
        "data_e.sort_values(by=['min', 'max'], ascending=True) # сортировка данных \n",
        "data.groupby('t1.acell').ne_id.mean() # найти среднее значение  \n",
        "data.groupby(['t1.acell', 'ne_id']).size().sort_values(ascending=False) # группировка по значению\n",
        "#%%\n",
        "#\n",
        "####\n",
        "###########\n",
        "###################   Other...\n",
        "df = data.append(new_row, ignore_index=True) # добавляет элемент в конец списка\n",
        "df = data.drop(['t1.macroregion'], axis = 1) # удалить столбец\n",
        "df_copied = df.copy() # поверхностное и глубокое копирование \n",
        "df['vol_new'] = round(df['ut_driver']) # округлить до выделенного значения \n",
        "#%%"
      ]
    }
  ]
}