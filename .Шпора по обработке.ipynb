{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN3gb8jl60V2fCathigGxo8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vitalyastiy/cheat-python/blob/main/.%D0%A8%D0%BF%D0%BE%D1%80%D0%B0%20%D0%BF%D0%BE%20%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импорт библиотек"
      ],
      "metadata": {
        "id": "kcNCXOIMOQQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import count\n",
        "from multiprocessing import cpu_count\n",
        "data = sns.load_dataset(\"titanic\")\n",
        "data_set1 = sns.load_dataset(\"taxis\")\n"
      ],
      "metadata": {
        "id": "9rLcmvJS3PBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# тест код\n",
        "\n"
      ],
      "metadata": {
        "id": "1qolRx9kGwPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Загрузка и выгрузка данных во фрейм"
      ],
      "metadata": {
        "id": "j0HjzJ66Iu60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv('тест.csv', parse_dates=['date'],  dayfirst=True) # автоконвертация текста в даты\n",
        "df = pd.read_csv('тест.csv', parse_dates=[['год','месяц','день']]) # «год», «месяц», «день», то при импорте данных их можно объединить, передав через параметр «parse_dates» список списка наименований столбцов\n",
        "\n",
        "df = pd.read_csv(r\"C:\\Users\\....Desktop\\nnn\\NN.csv\",  sep=',' , encoding='latin-1') #, index_col=0 - индекс \n",
        "df[:10].to_csv('saved_ratings.csv', index=False) # экспортироватъ первые десятъ строк\n",
        "data_copy = df.copy(deep=True) #shallow - поверхностное копирование фрейма \n",
        "df.to_csv('02-03_new.csv', header=True, index=False) # экспорт в csv\n",
        "pd.read_csv('file.csv', usecols=['A', 'B']) # - считать только нужные столбцы\n"
      ],
      "metadata": {
        "id": "zk_98fsmI5kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Регулирование количества столбцов или строк для отображения"
      ],
      "metadata": {
        "id": "UT7oRCq1wT4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 10)  #Сброс ограничений на количество выводимых рядов\n",
        "pd.set_option('display.max_columns', 10)  # Сброс ограничений на число столбцов\n",
        "pd.set_option('display.max_colwidth', 10)   # Сброс ограничений на количество символов в записи"
      ],
      "metadata": {
        "id": "90IuVmuLwUDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовка выборки\n"
      ],
      "metadata": {
        "id": "IzbY6puEJWrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data= data.rename(columns={\"gkgk\": \"colu\"}) # - переименоватъ столбец\n",
        "data.rename(columns=dict(sector_name='region', region='locale')) \n",
        "data.rename(index={0: 'firstEntry', 1: 'secondEntry'}) # переименовать индекс\n",
        "data.rename_axis('inde', axis='rows') # переименовать название \n",
        "\n",
        "data.sample(5) # data.head(5) # data.tail(5)  # выбор выборки\n",
        "df.sample(frac = 0.00005) # доля выборки\n",
        "data.head(3) # - вывести первые 3 записи\n",
        "data.tail(1) # - вывести последнюю записъ\n",
        "data[1:4] # - срез. вывести топ значений фрейма \n",
        "\n",
        "df.drop_duplicates (subset=['team', 'points']) # удалить дубли в определенных столбцах -- df.drop_duplicates (keep= False ) для полной очистки от дублей"
      ],
      "metadata": {
        "id": "XPn9UTZ3JaXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA"
      ],
      "metadata": {
        "id": "cCVIuDX7NBZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()/.tail() # - первые/последние строки\n",
        "data.info() # - получение сведений о фрейме \n",
        "data.dtypes # типы данных столбцов\n",
        "data.describe # - статистическая информация о фрейме\n",
        "data.pole.value_counts() # - подсчет количества уникалных значений\n",
        "data.pole.rank(method='dense', ascending = False) # - ранжировать, можно добавить метод dense\n",
        "len(data) # - вывести количество строк во фрейме \n",
        "\n",
        "data.shape/size # - размерность фрейма\n",
        "print(\"Shape of the DataFrame:\", df.shape)\n",
        "print(\"Number of rows:\", df.shape[0])\n",
        "print(\"Number of columns:\", df.shape[1])\n",
        "\n",
        "\n",
        "df.dtypes.value_counts() # - получитъ распределение по типам данных\n",
        "data.isnull().mean() # пропуски во фрейме /df.notnull().mean() - противоположная функция / data.isna().mean() - тоже самое, что isnull\n",
        "len(data['pole'].unique()) # - количество уникалъных строк во фрейме \n",
        "data['pole'].unique() # вывод всех уникальных значений\n",
        "data.nunique() #  - количество уникальных записей по столбцам или строкам\n",
        "data.columns.tolist() # - получитъ наименования столбцов списком/ -- type(df.columns) - получиить типы данных\n",
        "data.nlargest(5, 'pole') #- вернет наибольшее число и Nsmallest() - вернет наименьшее,  nsmallest() и nlargest() - противоположные\n",
        "\n",
        "data.dropna() # - очистить данные таблицу от наловых значений \n",
        "df = df.dropna (subset=['assists']) # - очистить данные где есть null в конкретном столбце \n",
        "data.dropna (thresh=50) # - очистить ниже определенного порога \n",
        "df = df.reset_index(drop=True) # - сбросить индекс \n",
        "\n",
        "\n",
        "data.pole.shift(1) # -смещение поля на одно значение\n",
        "data= data[['pole1', 'pole2']] # - создание нового фрейма из подмножества\n",
        "df.insert(loc=0'''(позиция)''', column='id', value=new_column) #- вставить столбец в определенное место\n",
        "replace = data.replace(to_replace = 0 , value -9999) # - заменить значения во фрейме\n",
        "data.rename({'Pole_old':'Pole_new'}, axis = 1 )\n",
        "data_filled = data.fillna(0) # - замена всех наловых значений на 0\n",
        "data.drop(columns = ['pole1', 'pole2']) # - удлить столбцы\n",
        "data.drop_duplicates(keep = 'first') # - удалить дубликаты\n",
        "data.set_index(['age']) #-установить индекс\n",
        "\n",
        "######### пропуски в колонках#######################\n",
        "plt.figure(figsize=(25,10)) \n",
        "#~df.isnull() вернет датафрейм, который содержит значения True для заполненных ячеек и False для пропущенных. Если бы мы написали df.isnull(), то получили бы датафрейм с логическим значением True для пропущенных значений и False для остальных значений.\n",
        "sns.heatmap(~df.isnull(), cbar=False, cmap=sns.cm.rocket_r).set_title('Темные области - заполненные данные, светлые - пропуски');"
      ],
      "metadata": {
        "id": "id5qUjEKND21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Фильтрация & сотрировка"
      ],
      "metadata": {
        "id": "Y97MqjL5N0Hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['поле'].isin(['F']) # вернет тру/фолс \n",
        "data['pole1'].where(data['pole1']>=25) # проверка структуры данных\n",
        "## метод фильтрации квери\n",
        "region = 'Center'\n",
        "quat = '2022-01-01'\n",
        "df_tall_named_sec = df_cor.query('Region == @region & Quarter == @quat')\n",
        "df_tall_named_sec\n",
        "#########################################################################################\n",
        "df.query(\"jobtitle.str.contains('captain', case=False)\")[['employeename',\t'basepay']] # case=False  аналог ловвер и аппер в sql\n",
        "\n",
        "data.filter(like='la', axis=1) # - выбрать столбцы в наименовании которых есть...\n",
        "data.drop(['colu'], axis=1).head() # - удаление столбца из фрейма данных\n",
        "data.append(data2.sum(axis=0), ignore_index=True) # - сумма по столбцу\n",
        "data[data['acell'].isin(['NN002998_I','NN002998_I'])] # -филътр\n",
        "data[data['acell'] == 'NN002998_I'] #(><) -филътр, для единственного значения\n",
        "data.sort_values('acell', ascending=True) # - сортировка фрейма \n",
        "df.pole.sort_values(ascending = False) # - второй вариант\n",
        "data.sort_values(by=['min', 'max'], ascending=True) # сортировка данных по нескольким столбцам  \n",
        "\n",
        "data['sector_name'].fillna('NaN').value_counts().sort_values(ascending=False) # найти NaN\n",
        "df_filter = df ['ID']. isin (['A001', 'C022', ...])  # выбор строк с конкретными идентификаторами\n",
        "\n",
        "\n",
        "m_data = data[data['sector_name'].isnull()] # шаг 1. кол-во нулевых\n",
        "n_data = len(m_data) #  шаг 2. кол-во нулевых\n",
        "n_data = data.sector_name.isnull().sum() # v2 кол-во нулевых\n",
        "m_data = pd.isnull(data.sector_name).sum() # v3 кол-во нулевых\n",
        "\n",
        "\n",
        "\n",
        "data[data[\"class\"].str.contains(\"Third\")]  # поиск подстроки"
      ],
      "metadata": {
        "id": "z4K_ZOytN2Z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Типы данных"
      ],
      "metadata": {
        "id": "BpKLQ1aAOPzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#все ячейки в “Date” конвертируются в даты. Затем лишние строки удаляются с помощью dropna().\n",
        "df['Date'] =pd.to_datetime(df['Date'])\n",
        "df.dropna(subset = ['Date'], inplace = True)\n",
        "\n",
        "no_2.resample(\"D\").mean().plot(style=\"-o\", figsize=(10, 5));\n",
        "\n",
        "df['new_month'] = pd.to_datetime(df['new_month']).dt.date # - перевести в дату\n",
        "data['col_new'] = data['col'].astype('float') # - изменить тип данных"
      ],
      "metadata": {
        "id": "9vdfyRoZORlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Объединение"
      ],
      "metadata": {
        "id": "kgNAQP2Wfkm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([A, B]) # по умолчанию axis = 0 \n",
        "pd.concat([A, B], axis=1) # левый к правой\n",
        "pd.concat([df1, df2], ignore_index=True)  #- union all\n",
        "pd.concat([X, Y]).drop_duplicates(keep=False) #- union\n",
        "\n",
        "df = pd.merge(exp_new, diss_new[['Region', 'Category_fit']], left_index= True, right_index=True, how='left') # джойн по индексу\n",
        "df = pd.merge(left=df_a, left_on['A'], right=df_b, right_on=['B'], how='inner') #- merge (вывод новых столбцов)\n",
        "df = pd.merge(df1, df2, how='inner', left_on=['t1.region', 't1.acell'], right_on = ['Region','ACELL'], suffixes = ['_c','_o']) #- suffixes - добавит суфиксы для столбцов, если есть столбцы с одинаковым названием\n"
      ],
      "metadata": {
        "id": "cJULguArfnr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### пример ### \n",
        "data_set1 = {'Name': ['Rohit', 'Mohit', 'Sohit', 'Arun', 'Shubh'], \n",
        "             'Roll no': ['01', '02', '03', '04', '05'], \n",
        "             'maths': ['93', '63', '74', '94', '83'], 'science': ['88', '55', '66', '94', '35'], 'english': ['93', '74', '84', '92', '87']} \n",
        "data_set2 = {'Name': ['Karan', 'Rishu', 'Swetank', 'Rishabh', 'Shuvam'],\n",
        "             'Roll no': ['06', '07', '08', '09', '10'], 'maths': ['95', '62', '64', '14', '63'], 'science': ['58', '59', '86', '74', '55'], 'english': ['96', '77', '89', '42', '87']} \n",
        "# Changing the above dictionary into dataframe\n",
        "df1 = pd.DataFrame(data_set1)\n",
        "df2 = pd.DataFrame(data_set2)\n",
        "# Concating both the dataframes\n",
        "pd.concat([df1, df2], keys=['Set1', 'Set2'], ignore_index=True) #axis=1)"
      ],
      "metadata": {
        "id": "4_fNyPFA09Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Агрегация"
      ],
      "metadata": {
        "id": "pWuIAP3ZX3_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('team')['points']. unique () # - группировка и посчет уникальных значений для одного столбца\n",
        "df.groupby(['pole1'], as_index=False).agg({ \"pole2\": pd.Series.nunique, \"pole3\": \"count\"}) #-группировка и посчет уникальных значений\n",
        "data.groupby('pole1').count() //mean() // median() // size() # - группировка по полю для всего df \n",
        "data.groupby('pole1').pole2.mean() # группировка по одному полю \n",
        "data.groupby('t1.acell')['t2.ne_id'].max().sort_index() # присваиваем индекс аселу и выводим макимальное значение из не_ид, сортируем от меньшего \n",
        "\n",
        "\n",
        "data.groupby('report_date').report_date.size() #(count-разница?) вывести количество записей, аналог гроуп бай\n",
        "data.groupby(['t1.acell']).ne_id.agg([len, min, max]) # группировка с агрегацией и расчетом \n",
        "\n",
        "\n",
        "\n",
        "data[[\"sex\", \"pclass\"]].pivot_table(values=\"pclass\", columns=\"sex\", aggfunc=\"mean\") # pivot "
      ],
      "metadata": {
        "id": "UfXVohj3X6Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Функции"
      ],
      "metadata": {
        "id": "weWBNCVTP_n-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функции"
      ],
      "metadata": {
        "id": "cM5RAHo2sKh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(lambda row: (row['pole1'],  row['pole2']), axis=1) # построчное применение функции\n",
        "level_map = {1: 'high', 2: 'medium', 3: 'low'} # преобразования данных\n",
        "df['c_level'] = df['c'].map(level_map) #\n",
        "###парс даты из произвольного формата###\n",
        "from datetime import datetime\n",
        "custom_datetime = lambda x: datetime.strptime(x, '%d%m%Y %H:%M:%S')\n",
        "df = pd.read_csv('тест2.csv', parse_dates=['date'], date_parser=custom_datetime)"
      ],
      "metadata": {
        "id": "dZZC9mjTsJ5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Пример: добавить новый столбец на основе условий\n",
        "def new_stat (row):\n",
        "  if 'Есть' in row['Вариант1']:\n",
        "    return 'Свой' \n",
        "  elif ...\n",
        "  else:\n",
        "    ('') \n",
        "df_full['flag']=df_full.apply(new_stat, axis = 1)"
      ],
      "metadata": {
        "id": "F82UeyBVQFxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Операции над значениями"
      ],
      "metadata": {
        "id": "cnCYhuytzgMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['pole1'].round(2) # округлить \n",
        "df['pole1'].nunique() # посчитать уникальнных\n",
        "df1[\"pole2\"].cumsum() # накопительный итог\n",
        "\n",
        "\n",
        "data[\"sex\"].replace({\"male\": \"m\", \"female\": \"f\"}) # изменить значения в подстроке"
      ],
      "metadata": {
        "id": "dBRI1Fn3zgZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loc iloc"
      ],
      "metadata": {
        "id": "Ssw6Wxx4ecFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.iloc[:0]  # вывести шапку \n",
        "data.iloc[552] # вывод СПИСОК строки по номеру\n",
        "data.iloc[552] # вывод строки по индексу\n",
        "data.iloc[0:5] # вывести первые 5 значений, с 0 до 4  \n",
        "data.loc[0:5]  # вывести первые 6 значений, с 0 до 5\n",
        "data.recdate  #data['recdate'] #data.iloc[:,0]#  вывод столбца в формате списка\n",
        "data.iloc[2,1] # data.loc[2,'ACELL'] вывести 3 строку из 2-ого столбца \n",
        "data.iloc[:3,1] #data.iloc[0:3,1]#data.iloc[[0,1,2],1]  вывести количество строк из столбца\n",
        "data.iloc[-3:,1] #  вывести второе значение снизу, второго столбца\n",
        "data.iloc[:, 0:2] # вывести всю информацию по двум столбцам  \n",
        "data.iloc[3, [1, 2, 3]] # список третьей строки по первым 3м столбцам\n",
        "data.loc[1:5, 'ACELL': 'Region'] # вывод таблицы с первой по пятаю, 2 столбца \n",
        "data.iloc[[0]] # вывести первую строку\n",
        "data.loc[:,['recdate','ACELL','Region','flag']] # print all\n",
        "data.loc[data.flag.isin(['100', '50'])] # филътр несколъко условий\n",
        "data.loc[data.flag.isnull()] \n",
        "data.loc[data.flag.notnull()]  \n",
        "data[data['t2.ne_id'].isnull()] # вариация поиска нулевых значений\n",
        "############## Примеры фильтров выводом фрейма \n",
        "data.loc[data['ACELL'] == 'NN000231_A'] # вывести отфильтрованную таблицу\n",
        "data.loc[data.ACELL == 'NN000231_A'] # то же что и предыдущее\n",
        "data.loc[data.flag == '0'] # филътр на таблицу с выводом всего датафрейма \n",
        "data.loc[(data.flag == '0') & (data.recdate =='2022-02-28 23:00')] # склеенный фильтр на таблицу\n",
        "data.loc[(data['ACELL'] == 'NN000231_A' ) & (data['recdate'] == '2022-02-20 16:00'), 'recdate':'flag'] # пример склеенного фильтра\n",
        "###### replace ###### \n",
        "data.loc[data['ACELL'] == 'NN000231_A'] = 'BIG'\n",
        "data.loc[data['ACELL'] == 'NN000231_A', 'ACELL':'Mean_flag_integrity 4G (%)'].head() # пример реплэйса с фильтром и выводом"
      ],
      "metadata": {
        "id": "LJPO2X0Sej8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Визуализация"
      ],
      "metadata": {
        "id": "ICTxlRpNB0nK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "resample"
      ],
      "metadata": {
        "id": "k5U-_iIzB1da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_set1.set_index('pickup').resample(\"D\").median().plot(style=\"-o\", figsize=(10, 5)) #установить индекс с ресамплом построить ряд\n",
        "#Resample нужен для перерасчета или изменения шага времени данных, можно изменять частоту временных данных и изменять их размер\n",
        "#Создаем временной ряд с данными о продажах ежедневно\n",
        "#Изменяем размер данных: ежедневные данные на среднемесячные данные  ---   monthly_temp = daily_temp.resample('M').mean()"
      ],
      "metadata": {
        "id": "inwX0jqyB1si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Итерации"
      ],
      "metadata": {
        "id": "Q22IUs73wxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Иттерации по фрейму"
      ],
      "metadata": {
        "id": "pJ9e_kWr9n7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## создать тестовые данные\n",
        "df = pd.DataFrame([[1, \"A\"], [2, \"B\"], [3, \"C\"]], columns = [\"col1\", \"col2\"])\n",
        "print(df)\n",
        "# итерация по тестовым данным\n",
        "print(\"Method 1:\", end = \" \")\n",
        "for index in range(len(df)):\n",
        "    print(df[\"col1\"][index], end = \" \")\n",
        "\n",
        "print(\"\\nMethod 2:\", end = \" \")\n",
        "for index, row in df.iterrows():\n",
        "    print(row[\"col1\"], end = \" \")\n",
        "\n",
        "print(\"\\nMethod 3:\", end = \" \")\n",
        "for row in df.itertuples(): \n",
        "    print(row.col1, end = \" \")"
      ],
      "metadata": {
        "id": "ni33tQry8a1p",
        "outputId": "edef5739-ab80-4a37-f194-d3bba73ead90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   col1 col2\n",
            "0     1    A\n",
            "1     2    B\n",
            "2     3    C\n",
            "Method 1: 1 2 3 \n",
            "Method 2: 1 2 3 \n",
            "Method 3: 1 2 3 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# итерация с примером \n",
        "data=data.rename(columns={\"class\": \"class_\"}) \n",
        "f = 0\n",
        "for i in data.itertuples(): \n",
        "    if i.class_ ==  'Third':\n",
        "      f += 1 \n",
        "print(f)\n",
        "f = 0\n",
        "for i, row in data.iterrows():\n",
        "  if row['class_'] == 'Third':\n",
        "    f += 1 \n",
        "print(f)\n",
        "\n",
        "f = 0\n",
        "for i in range(len(data)):\n",
        "  if data['class_'][i] == 'Third':\n",
        "    f += 1 \n",
        "print(f)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pSsQjgI_2BT",
        "outputId": "7af460d6-51bc-4a30-a58c-422686819340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "491\n",
            "491\n",
            "491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Примеры"
      ],
      "metadata": {
        "id": "20AzRySy8774"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SQL Lead и Lag на питоне"
      ],
      "metadata": {
        "id": "niC2ScyqUskz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'DATE': [1, 2, 3, 4, 5],\n",
        "                   'VOLUME': [100, 200, 300,400,500],\n",
        "                   'PRICE': [214, 234, 253,272,291]})\n",
        "#Мы можем легко вычислить среднюю цену акций за три последних дня и создать новый столбец, как показано ниже: \n",
        "df['LAST_3_DAYS_AVE_PRICE'] = (df['PRICE'].shift(1,fill_value=0) + \n",
        "                               df['PRICE'].shift(2,fill_value=0) + \n",
        "                               df['PRICE'].shift(3,fill_value=0))/3\n",
        "\n",
        "#Можно пойти дальше и получить значение из следующего временного интервала или ряда: \n",
        "df['TOMORROW_PRICE'] = df['PRICE'].shift(-1,fill_value=0)"
      ],
      "metadata": {
        "id": "bVBAD-5IUvGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Добавление нового столбца в заданном месте датафрейма \n",
        "df['Population density'] = df['City Population']/df['City Area']\n",
        "df.insert(loc=3, column='Population density', value=(df['City Population']/df['City Area']))"
      ],
      "metadata": {
        "id": "yPpqkp-uVRZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#для нахождения уникальных значений:\n",
        "b = pd.Series(['ab','bc','cd',1,'cd','cd','bc','ab','bc',1,2,3,2,3,np.nan,1,np.nan])\n",
        "b.value_counts()"
      ],
      "metadata": {
        "id": "4GNvAJdHVRhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Выбор столбца на основе типа данных\n",
        "df.select_dtypes(exclude=['int64','float64'])\n",
        "df.select_dtypes(include='number',exclude='float64')"
      ],
      "metadata": {
        "id": "rbNiwxM3Yiwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mask() для условия if-else #Обратимся к датафрейму, в котором нужно изменить знак всех элементов, кратных двум без остатка. \n",
        "df = pd.DataFrame(np.arange(15).reshape(-1, 3), columns=['A', 'B','C'])\n",
        "print(df)\n",
        "#С помощью mask проверяем делится ли элемент на 2 без остатка. \n",
        "#При соотвествии условию меняем знак элемента\n",
        "df.mask(df % 2 == 0,-df)"
      ],
      "metadata": {
        "id": "pNKGXws9Y7WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fJ2JT-3095En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYjoo6FZzUnL"
      },
      "outputs": [],
      "source": [
        "###################   Other...\n",
        "df = data.append(new_row, ignore_index=True) # добавляет элемент в конец списка\n",
        "df = data.drop(['t1.macroregion'], axis = 1) # удалить столбец\n",
        "df_copied = df.copy() # поверхностное и глубокое копирование \n",
        "df['vol_new'] = round(df['ut_driver']) # округлить до выделенного значения \n",
        "\n",
        "# Перебор строк во фрейме()\n",
        "for idx,row in df2[:1].iterrows():\n",
        "    print(idx, row)\n",
        "#%%\n",
        "\n",
        "data ['acell'].tolist() # - перевести в список стлбец\n",
        "data['colu'] = True # - добавитъ столбец во фрейм данных\n",
        "\n",
        "###кейс с фильтрацией:\n",
        "data['t1.region'].unique() #  вывести уникальные значения фрейма\n",
        "data = data.set_index('t1.region') # присвоить индекс\n",
        "data.drop(['RYAZAN', 'TVER'],axis = 0) # установить фильтрацию по столбцу и дропнуть эти данные во фрейме "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2lb4Xhwjli4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "am4kn17wli-2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}